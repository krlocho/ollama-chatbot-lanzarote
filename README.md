# 游꺗 Ollama Chatbot Local

Este es un proyecto de chatbot web ligero que se ejecuta completamente en local. Utiliza **Ollama** como backend para la generaci칩n de lenguaje y una interfaz de usuario simple construida con HTML, CSS (con tem치tica de Lanzarote) y JavaScript.



---

## 游 Requisitos Previos

Para ejecutar este chatbot, necesitas tener instalados y funcionando los siguientes componentes:

1.  **Ollama:** El servidor de modelos de lenguaje local.
    * https://ollama.com
2.  **Un Modelo de Lenguaje:** Debes tener al menos un modelo descargado. Recomendamos `llama2` o `mistral` para empezar.

    ```bash
    # Ejemplo:
    ollama pull mistral
    ```
3.  **Un Servidor Web Local Simple:** Para evitar problemas de seguridad del navegador (CORS), el frontend debe servirse a trav칠s de HTTP (no abrir el archivo directamente).

---

## 丘뙖잺 Instalaci칩n y Configuraci칩n

Sigue estos pasos para poner en marcha el chatbot en tu m치quina local.

### 1. Clonar el Repositorio

